{"cells":[{"cell_type":"markdown","metadata":{},"source":["## **Algorithmic Detection of Credit Card Defaulting**\n","#### **Final Project Phase 2**\n","*Tanvi Namjoshi, Dylan Van Bramer, Madeline Demers, Ella White*\n","\n","In this report, we perform an initial examination of the dataset obtained from UC Irvine in 2016, focusing on credit card clients in Taiwan who have defaulted. Building a predictive model to assess the likelihood of customer defaulting requires fairness to prevent discrimination based on sensitive features. Defaulting on a credit card is defined as failing to make the minimum payment for at least 180 days. We plan to explore whether we can find a risk prediction model that is fair across different subgroups (male/female, education) that still remains accurate. \n","\n","The original source for the data can be found here: [https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients](https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients)"]},{"cell_type":"markdown","metadata":{},"source":["#### **Previous Work**\n","Our previous work involved auditing the Rotterdam welfare fraud detection algorithm using the synthetic dataset and model obtained by the data journalists at Lighthouse Reports and Wired. We spent the first half of our time working on Phase 2 using that dataset. This included translating the feature names from Dutch to English, calculating summary statistics for the dataset, and attempting to train an unsupervised model on the data provided. However, we decided to pivot from this to the credit card defaulting data for two main reasons. First, as noted in the methodology article from Lighthouse Reports, we do not have any of the target values about whether or not the individual did infact commit fraud. This made it extremely difficult for us to analyze the accuracy of the model used by the government in Rotterdam as well as our own model. Realistically, we would have only been able to use statisical parity as a metric for fairness, and we would have no ground truth labels. Secondly, the provided model was in R, and while we were able to load it into our notebook, the strucutre of the model was extremely unclear. We were unable to successfully use the Rotterdam model on the dataset. For these reasons we have pivoted to algorithmic detection of credit card defaulting."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","from sklearn.cluster import KMeans\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{},"source":["#### **Data Import and Cleaning**"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LIMIT_BAL</th>\n","      <th>SEX</th>\n","      <th>EDUCATION</th>\n","      <th>MARRIAGE</th>\n","      <th>AGE</th>\n","      <th>PAY_0</th>\n","      <th>PAY_2</th>\n","      <th>PAY_3</th>\n","      <th>PAY_4</th>\n","      <th>PAY_5</th>\n","      <th>...</th>\n","      <th>BILL_AMT4</th>\n","      <th>BILL_AMT5</th>\n","      <th>BILL_AMT6</th>\n","      <th>PAY_AMT1</th>\n","      <th>PAY_AMT2</th>\n","      <th>PAY_AMT3</th>\n","      <th>PAY_AMT4</th>\n","      <th>PAY_AMT5</th>\n","      <th>PAY_AMT6</th>\n","      <th>default payment next month</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20000</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-2</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>689</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>120000</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>26</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>3272</td>\n","      <td>3455</td>\n","      <td>3261</td>\n","      <td>0</td>\n","      <td>1000</td>\n","      <td>1000</td>\n","      <td>1000</td>\n","      <td>0</td>\n","      <td>2000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>90000</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>14331</td>\n","      <td>14948</td>\n","      <td>15549</td>\n","      <td>1518</td>\n","      <td>1500</td>\n","      <td>1000</td>\n","      <td>1000</td>\n","      <td>1000</td>\n","      <td>5000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50000</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>28314</td>\n","      <td>28959</td>\n","      <td>29547</td>\n","      <td>2000</td>\n","      <td>2019</td>\n","      <td>1200</td>\n","      <td>1100</td>\n","      <td>1069</td>\n","      <td>1000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50000</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>57</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>20940</td>\n","      <td>19146</td>\n","      <td>19131</td>\n","      <td>2000</td>\n","      <td>36681</td>\n","      <td>10000</td>\n","      <td>9000</td>\n","      <td>689</td>\n","      <td>679</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 24 columns</p>\n","</div>"],"text/plain":["   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4   \n","0      20000    2          2         1   24      2      2     -1     -1  \\\n","1     120000    2          2         2   26     -1      2      0      0   \n","2      90000    2          2         2   34      0      0      0      0   \n","3      50000    2          2         1   37      0      0      0      0   \n","4      50000    1          2         1   57     -1      0     -1      0   \n","\n","   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3   \n","0     -2  ...          0          0          0         0       689         0  \\\n","1      0  ...       3272       3455       3261         0      1000      1000   \n","2      0  ...      14331      14948      15549      1518      1500      1000   \n","3      0  ...      28314      28959      29547      2000      2019      1200   \n","4      0  ...      20940      19146      19131      2000     36681     10000   \n","\n","   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n","0         0         0         0                           1  \n","1      1000         0      2000                           1  \n","2      1000      1000      5000                           0  \n","3      1100      1069      1000                           0  \n","4      9000       689       679                           0  \n","\n","[5 rows x 24 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Import the data\n","og_df = pd.read_csv('UCI_CC_defaulting.csv', skiprows=[0])\n","\n","# Clean the data by dropping the additional first column, which is just an ID. \n","# We can use index number as identification.  \n","og_df.drop(og_df.columns[0], axis=1, inplace=True)\n","\n","# Display the Data\n","og_df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["LIMIT_BAL                     0\n","SEX                           0\n","EDUCATION                     0\n","MARRIAGE                      0\n","AGE                           0\n","PAY_0                         0\n","PAY_2                         0\n","PAY_3                         0\n","PAY_4                         0\n","PAY_5                         0\n","PAY_6                         0\n","BILL_AMT1                     0\n","BILL_AMT2                     0\n","BILL_AMT3                     0\n","BILL_AMT4                     0\n","BILL_AMT5                     0\n","BILL_AMT6                     0\n","PAY_AMT1                      0\n","PAY_AMT2                      0\n","PAY_AMT3                      0\n","PAY_AMT4                      0\n","PAY_AMT5                      0\n","PAY_AMT6                      0\n","default payment next month    0\n","dtype: int64\n","No missing values found.\n"]}],"source":["#In order to clean, we first check for missing values\n","missing_values = og_df.isnull().sum()\n","print(missing_values)\n","\n","if missing_values.sum() == 0:\n","    print(\"No missing values found.\")\n","else:\n","    print(\"There are missing values.\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["LIMIT_BAL                     int64\n","SEX                           int64\n","EDUCATION                     int64\n","MARRIAGE                      int64\n","AGE                           int64\n","PAY_0                         int64\n","PAY_2                         int64\n","PAY_3                         int64\n","PAY_4                         int64\n","PAY_5                         int64\n","PAY_6                         int64\n","BILL_AMT1                     int64\n","BILL_AMT2                     int64\n","BILL_AMT3                     int64\n","BILL_AMT4                     int64\n","BILL_AMT5                     int64\n","BILL_AMT6                     int64\n","PAY_AMT1                      int64\n","PAY_AMT2                      int64\n","PAY_AMT3                      int64\n","PAY_AMT4                      int64\n","PAY_AMT5                      int64\n","PAY_AMT6                      int64\n","default payment next month    int64\n","dtype: object\n"]}],"source":["# Next, we check the data types. \n","data_types = og_df.dtypes\n","print(data_types)"]},{"cell_type":"markdown","metadata":{},"source":["To clean our data further, we will re-format some of this information using one-hot encoding. From our data source, we know the dataset is structured as follows: \n","* SEX: 1 = male, 2 = female \n","* EDUCATION: 1 = graduate school, 2= university; 3 = high school; 4 = others\n","* MARRIAGE: 1 = married; 2 = single; 3 = others"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["resuts for SEX column match expectations\n","removed EDUCATION columns that did not mach expectations\n","removed MARRIAGE columns that did not mach expectations\n","The number of datapoints with bad values was  399\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LIMIT_BAL</th>\n","      <th>AGE</th>\n","      <th>PAY_0</th>\n","      <th>PAY_2</th>\n","      <th>PAY_3</th>\n","      <th>PAY_4</th>\n","      <th>PAY_5</th>\n","      <th>PAY_6</th>\n","      <th>BILL_AMT1</th>\n","      <th>BILL_AMT2</th>\n","      <th>...</th>\n","      <th>default payment next month</th>\n","      <th>SEX_male</th>\n","      <th>SEX_female</th>\n","      <th>graduate_education</th>\n","      <th>university_education</th>\n","      <th>highschool_education</th>\n","      <th>other_education</th>\n","      <th>married</th>\n","      <th>single</th>\n","      <th>marriage_other</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20000</td>\n","      <td>24</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-2</td>\n","      <td>-2</td>\n","      <td>3913</td>\n","      <td>3102</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>120000</td>\n","      <td>26</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2682</td>\n","      <td>1725</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>90000</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>29239</td>\n","      <td>14027</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50000</td>\n","      <td>37</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>46990</td>\n","      <td>48233</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50000</td>\n","      <td>57</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8617</td>\n","      <td>5670</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 30 columns</p>\n","</div>"],"text/plain":["   LIMIT_BAL  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1   \n","0      20000   24      2      2     -1     -1     -2     -2       3913  \\\n","1     120000   26     -1      2      0      0      0      2       2682   \n","2      90000   34      0      0      0      0      0      0      29239   \n","3      50000   37      0      0      0      0      0      0      46990   \n","4      50000   57     -1      0     -1      0      0      0       8617   \n","\n","   BILL_AMT2  ...  default payment next month  SEX_male  SEX_female   \n","0       3102  ...                           1         0           1  \\\n","1       1725  ...                           1         0           1   \n","2      14027  ...                           0         0           1   \n","3      48233  ...                           0         0           1   \n","4       5670  ...                           0         1           0   \n","\n","   graduate_education  university_education  highschool_education   \n","0                   0                     1                     0  \\\n","1                   0                     1                     0   \n","2                   0                     1                     0   \n","3                   0                     1                     0   \n","4                   0                     1                     0   \n","\n","   other_education  married  single  marriage_other  \n","0                0        1       0               0  \n","1                0        0       1               0  \n","2                0        0       1               0  \n","3                0        1       0               0  \n","4                0        1       0               0  \n","\n","[5 rows x 30 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Finished creating one-hot encoding\n"]}],"source":["# Create the one-hot encodings. For each feature, we first assert that all the info provided by the dataset creators is accurate. \n","# After that, we create the one-hot encodings\n","\n","clean_df = og_df\n","# SEX\n","if clean_df[\"SEX\"].nunique() == 2 and np.array_equal(clean_df[\"SEX\"].unique(), np.array([2,1])):\n","  print(\"resuts for SEX column match expectations\")\n","else:\n","  # the above assertion failed. Let us remove all rows that do not match our expectations\n","  clean_df = clean_df[clean_df['SEX'].between(1,2)]\n","  assert (clean_df[\"SEX\"].nunique() == 2) \n","  print(\"removed SEX columns that did not mach expectations\")\n","\n","\n","# EDUCATION\n","if clean_df[\"EDUCATION\"].nunique() == 4:\n","  print(\"resuts for EDUCATION column match expectations\")\n","else:\n","  # the above assertion failed. Let us remove all rows that do not match our expectations\n","  clean_df = clean_df[clean_df['EDUCATION'].between(1, 4)]\n","  assert (clean_df[\"EDUCATION\"].nunique() == 4) \n","  print(\"removed EDUCATION columns that did not mach expectations\")\n","\n","\n","# MARRIAGE\n","if clean_df[\"MARRIAGE\"].nunique() == 3:\n","  print(\"resuts for MARRIAGE column match expectations\")\n","else:\n","  # the above assertion failed. Let us remove all rows that do not match our expectations\n","  clean_df = clean_df[clean_df['MARRIAGE'].between(1, 3)]\n","  assert (clean_df[\"MARRIAGE\"].nunique() == 3) \n","  print(\"removed MARRIAGE columns that did not mach expectations\")\n","\n","old_rows = og_df.count()[0]\n","new_rows = clean_df.count()[0]\n","print(\"The number of datapoints with bad values was \", old_rows - new_rows)\n","\n","clean_df = pd.get_dummies(clean_df, columns=['SEX', 'EDUCATION', 'MARRIAGE' ], dtype=int)\n","column_names = {\"SEX_1\": \"SEX_male\", \"SEX_2\": \"SEX_female\", \"EDUCATION_1\": \"graduate_education\", \"EDUCATION_2\": \"university_education\", \"EDUCATION_3\": \"highschool_education\", \"EDUCATION_4\": \"other_education\"}\n","column_names.update({\"MARRIAGE_1\": \"married\", \"MARRIAGE_2\": \"single\", \"MARRIAGE_3\": \"marriage_other\"})\n","clean_df.rename(columns=column_names, errors=\"raise\", inplace=True)\n","display(clean_df.head())\n","\n","print(\"Finished creating one-hot encoding\")\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#TODO: Do we also want to do past payment? The info is as follows:\n","#Past payment: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above."]},{"cell_type":"markdown","metadata":{},"source":["#### **Summary Statistics**\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Part 2(a)"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking at the whole dataset:\n","There are 29601 rows of data in the dataframe\n","There are 30 features/columns in the dataframe\n","\n","Looking at the dataset by gender:\n","The number of data points where the person's gender is female is:  17855\n","The number of data points where the person's gender is NOT female is:  11746\n","\n","Looking at the dataset by education:\n","The number of data points where the person has a graduate education is:  10581\n","The number of data points where the person has a univeristy education is:  14024\n","The number of data points where the person has a high school education is:  4873\n","The number of data points where the person has none of the above is:  123\n","\n","Looking at the dataset by marriage status:\n","There are 13477 datapoints where the person is married\n","There are 15806 datapoints where the person is single\n","There are 318 datapoints where the person identifies as neither married or single\n","\n","Looking at the dataset by AGE:\n","The number of data points where the person is under 50:  26967\n","The number of data points where the person is over 50:  2634\n"]}],"source":["# Part 2 (a)\n","rows = clean_df.count()[0]\n","columns = len(clean_df.columns)\n","print(\"Looking at the whole dataset:\")\n","print(\"There are\", rows, \"rows of data in the dataframe\")\n","print(\"There are\", columns, \"features/columns in the dataframe\")\n","\n","\n","#Per sensitive attribute subgroup\n","\n","#Gender \n","female_idx = clean_df.index[clean_df[\"SEX_female\"]==1]\n","male_idx = clean_df.index[clean_df[\"SEX_male\"] == 1]\n","print(\"\\nLooking at the dataset by gender:\")\n","print(\"The number of data points where the person's gender is female is: \", len(female_idx))\n","print(\"The number of data points where the person's gender is NOT female is: \", len(male_idx))\n","\n","#Education \n","graduate_idx = clean_df.index[clean_df[\"graduate_education\"]==1]\n","university_idx = clean_df.index[clean_df[\"university_education\"] == 1]\n","highschool_idx = clean_df.index[clean_df[\"highschool_education\"] == 1]\n","other_education_idx = clean_df.index[clean_df[\"other_education\"] == 1]\n","\n","print(\"\\nLooking at the dataset by education:\")\n","print(\"The number of data points where the person has a graduate education is: \", len(graduate_idx))\n","print(\"The number of data points where the person has a univeristy education is: \", len(university_idx))\n","print(\"The number of data points where the person has a high school education is: \", len(highschool_idx))\n","print(\"The number of data points where the person has none of the above is: \", len(other_education_idx))\n","\n","\n","# Marriage Status\n","single_df = clean_df[clean_df['single'] == 1]\n","married_df = clean_df[clean_df['married'] == 1]\n","other_df = clean_df[clean_df['marriage_other'] == 1]\n","rows_married = married_df.shape[0]  \n","rows_single = single_df.shape[0]  \n","rows_other = other_df.shape[0]  \n","\n","print(\"\\nLooking at the dataset by marriage status:\")\n","print(\"There are\", rows_married, \"datapoints where the person is married\")\n","print(\"There are\", rows_single, \"datapoints where the person is single\")\n","print(\"There are\", rows_other, \"datapoints where the person identifies as neither married or single\")\n","\n","#AGE \n","under_fifty = clean_df.index[clean_df[\"AGE\"]<50]\n","over_fifty = clean_df.index[clean_df[\"AGE\"] >= 50]\n","\n","print(\"\\nLooking at the dataset by AGE:\")\n","print(\"The number of data points where the person is under 50: \", len(under_fifty))\n","print(\"The number of data points where the person is over 50: \", len(over_fifty))\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Part 2(b)\n","Our outcome variable of interest is whether the individual defaults on their payment next month. In our dataset that is the variable `default payment next month`, which is either 0 or 1."]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Outcome variable: default payment next month\n","\n","Overall Statistics\n","Mean: 0.2231343535691362\n","Median: 0.0\n","Standard Deviation: 0.4163547406844319\n"]}],"source":["outcome_variable = 'default payment next month'\n","\n","mean_value = clean_df[outcome_variable].mean()\n","median_value = clean_df[outcome_variable].median()\n","std_dev_value = clean_df[outcome_variable].std()\n","\n","# Print the results\n","print(\"Outcome variable:\", outcome_variable)\n","print(\"\\nOverall Statistics\")\n","print(\"Mean:\", mean_value)\n","print(\"Median:\", median_value)\n","print(\"Standard Deviation:\", std_dev_value)\n"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Statistics by Gender\n","Mean for Females: 0.20968916269952395\n","Median for Females : 0.0\n","Standard Deviation for Females: 0.40709814501924513\n","Mean for Males: 0.24357227992508088\n","Median for Males: 0.0\n","Standard Deviation for Males: 0.4292557646242155\n"]}],"source":["\n","#Gender\n","print(\"\\nStatistics by Gender\")\n","mean_value = clean_df[outcome_variable][female_idx].mean()\n","median_value = clean_df[outcome_variable][female_idx].median()\n","std_dev_value = clean_df[outcome_variable][female_idx].std()\n","print(\"Mean for Females:\", mean_value)\n","print(\"Median for Females :\", median_value)\n","print(\"Standard Deviation for Females:\", std_dev_value)\n","\n","mean_value = clean_df[outcome_variable][male_idx].mean()\n","median_value = clean_df[outcome_variable][male_idx].median()\n","std_dev_value = clean_df[outcome_variable][male_idx].std()\n","print(\"Mean for Males:\", mean_value)\n","print(\"Median for Males:\", median_value)\n","print(\"Standard Deviation for Males:\", std_dev_value)"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Statistics by Education\n","Mean for People with Graduate Education: 0.19242037614592195\n","Median for People with Graduate Education  0.0\n","Standard Deviation for Graduate Education: 0.39422006872642057\n","Mean for People with University Education: 0.2373787792355961\n","Median for People with University Education: 0.0\n","Standard Deviation for University Education: 0.42549148512838436\n","Mean for People with High School Education: 0.25302688282372254\n","Median for People with High School Education  0.0\n","Standard Deviation for High School Education: 0.43479083865008655\n","Mean for People with Other Education: 0.056910569105691054\n","Median for People with Other Education: 0.0\n","Standard Deviation for Other Education: 0.23261919236784867\n"]}],"source":["#Edcuation\n","print(\"\\nStatistics by Education\")\n","mean_value = clean_df[outcome_variable][graduate_idx].mean()\n","median_value = clean_df[outcome_variable][graduate_idx].median()\n","std_dev_value = clean_df[outcome_variable][graduate_idx].std()\n","print(\"Mean for People with Graduate Education:\", mean_value)\n","print(\"Median for People with Graduate Education \", median_value)\n","print(\"Standard Deviation for Graduate Education:\", std_dev_value)\n","\n","\n","mean_value = clean_df[outcome_variable][university_idx].mean()\n","median_value = clean_df[outcome_variable][university_idx].median()\n","std_dev_value = clean_df[outcome_variable][university_idx].std()\n","print(\"Mean for People with University Education:\", mean_value)\n","print(\"Median for People with University Education:\", median_value)\n","print(\"Standard Deviation for University Education:\", std_dev_value)\n","\n","mean_value = clean_df[outcome_variable][highschool_idx].mean()\n","median_value = clean_df[outcome_variable][highschool_idx].median()\n","std_dev_value = clean_df[outcome_variable][highschool_idx].std()\n","print(\"Mean for People with High School Education:\", mean_value)\n","print(\"Median for People with High School Education \", median_value)\n","print(\"Standard Deviation for High School Education:\", std_dev_value)\n","\n","\n","mean_value = clean_df[outcome_variable][other_education_idx].mean()\n","median_value = clean_df[outcome_variable][other_education_idx].median()\n","std_dev_value = clean_df[outcome_variable][other_education_idx].std()\n","print(\"Mean for People with Other Education:\", mean_value)\n","print(\"Median for People with Other Education:\", median_value)\n","print(\"Standard Deviation for Other Education:\", std_dev_value)"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Statistics by Marriage\n","Mean for married people: 0.2368479631965571\n","Median for married people: 0.0\n","Standard Deviation for married people: 0.425163989931608\n","Mean for single people: 0.2106162216879666\n","Median for single people: 0.0\n","Standard Deviation for single people: 0.40775917907231995\n","Mean for People with Other Marriage Status: 0.2641509433962264\n","Median for People with Other Marriage Status: 0.0\n","Standard Deviation for Other Marriage: 0.4415749014017929\n"]}],"source":["#Edcuation\n","print(\"\\nStatistics by Marriage\")\n","mean_value = married_df[outcome_variable].mean()\n","median_value = married_df[outcome_variable].median()\n","std_dev_value = married_df[outcome_variable].std()\n","print(\"Mean for married people:\", mean_value)\n","print(\"Median for married people:\", median_value)\n","print(\"Standard Deviation for married people:\", std_dev_value)\n","\n","\n","mean_value = single_df[outcome_variable].mean()\n","median_value = single_df[outcome_variable].median()\n","std_dev_value = single_df[outcome_variable].std()\n","print(\"Mean for single people:\", mean_value)\n","print(\"Median for single people:\", median_value)\n","print(\"Standard Deviation for single people:\", std_dev_value)\n","\n","mean_value = other_df[outcome_variable].mean()\n","median_value = other_df[outcome_variable].median()\n","std_dev_value = other_df[outcome_variable].std()\n","print(\"Mean for People with Other Marriage Status:\", mean_value)\n","print(\"Median for People with Other Marriage Status:\", median_value)\n","print(\"Standard Deviation for Other Marriage:\", std_dev_value)"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Statistics by Age\n","Mean for People Under 50: 0.21989839433381542\n","Median for People Under 50  0.0\n","Standard Deviation for People Under 50: 0.41418528699333007\n","Mean for People Over 50: 0.25626423690205014\n","Median for People Over 50  0.0\n","Standard Deviation for People Over 50: 0.4366523376693046\n"]}],"source":["print(\"\\nStatistics by Age\")\n","\n","mean_value = clean_df[outcome_variable][under_fifty].mean()\n","median_value = clean_df[outcome_variable][under_fifty].median()\n","std_dev_value = clean_df[outcome_variable][under_fifty].std()\n","print(\"Mean for People Under 50:\", mean_value)\n","print(\"Median for People Under 50 \", median_value)\n","print(\"Standard Deviation for People Under 50:\", std_dev_value)\n","\n","mean_value = clean_df[outcome_variable][over_fifty].mean()\n","median_value = clean_df[outcome_variable][over_fifty].median()\n","std_dev_value = clean_df[outcome_variable][over_fifty].std()\n","print(\"Mean for People Over 50:\", mean_value)\n","print(\"Median for People Over 50 \", median_value)\n","print(\"Standard Deviation for People Over 50:\", std_dev_value)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Part 2(c)\n","c. Plot at least as many figures as your # group members, and explain concisely but\n","meaningfully what the plot shows in markdown text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### **Research Question, Hypotheses, and Analysis Plan**"]},{"cell_type":"markdown","metadata":{},"source":["a. Concretely, what is (are) your research question(s)? Be specific: what are the\n","inputs, outputs, and evaluation metrics you are interested in, and why?\n","b. What are your hypotheses?\n","i. E.g., do you notice any potential biases from your summary statistics?\n","What are they, and why might these exist?\n","c. What analyses are you going to run (in section 4) to test your hypotheses\n","presented above?"]},{"cell_type":"markdown","metadata":{},"source":["Research Question: Is it possible to fairly predict the risk of an indvidual defaulting on their credit card?\n","Hypotheses?: young, ummarried people that are college or lower level of education (irresponsible when younger?), take into account the fact that this is data from Tawian not USA\n","Evaluation Metrics: \n","- calibrationl goal to improve this\n","- statisical parity; at least evaluate this"]},{"cell_type":"markdown","metadata":{},"source":["#### **Modeling**"]},{"cell_type":"markdown","metadata":{},"source":["a. You should run at least as many analyses as there are # group members.\n","i. E.g., if you have 3 group members, and your project is to find a risk\n","prediction model / method that balances fairness with accuracy, you may\n","want to try one logistic regression with [a subset of variables], one logistic\n","regression with [upsampling methods for minority groups in the training\n","data], and one random forest with [a different subset of variables].\n","ii. E.g., if you have 3 group members, and your project is to audit a dataset\n","for diversity, you could perform three separate analyses of the data – one\n","comparing the dataset makeup to the true underlying distribution by one sensitive attribute, a second similar comparison by a different sensitive\n","attribute, and an insertion of additional (collected or synthetic) data to\n","balance the dataset by sensitive attributes.\n","b. You should report evaluation metrics for each model, including by subgroup (for\n","your sensitive attribute(s) of interest).\n","i. If applicable, you should also include significance testing (e.g., report\n","p-values).\n","c. You should include informative plot(s) about your models.\n","i. E.g., you could plot ROC curves, or comparisons of fairness metrics\n","and/or performance across different models.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('UCI_CC_defaulting.csv')\n","df.head()\n","df = df.drop(df.columns[0], axis=1)\n","new_columns = df.iloc[0]\n","df = df.drop(0)\n","# Rename columns\n","df.columns = new_columns\n","\n","df = df.reset_index(drop=True)\n","\n","# Obtain our X and Y values\n","y = df['default payment next month']\n","y = [int(Y) for Y in y]\n","X = df.drop('default payment next month', axis=1)\n","d1 = X.copy()\n","d2 = X.copy()\n","d3 = X.copy()\n","d4 = X.copy()\n","# Split into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n","# We have one matrix of values for each of our data sets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Include all features\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","# Don't evaluate on sensitive features\n","cols = ['EDUCATION', 'MARRIAGE', 'SEX', 'AGE']\n","d1 = d1.drop(cols, axis=1)\n","X_train1, X_test1, y_train1, y_test1 = train_test_split(d1, y, test_size=0.3)\n","# Don't consider marriage\n","d2 = d2.drop('MARRIAGE', axis=1)\n","X_train2, X_test2, y_train2, y_test2 = train_test_split(d2, y, test_size=0.3)\n","display(d2)\n","# Don't consider age or education\n","cols = ['EDUCATION','AGE']\n","d3 = d3.drop(cols,axis=1)\n","X_train3, X_test3, y_train3, y_test3 = train_test_split(d3, y, test_size=0.3)\n","display(d3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Data\n","km = KMeans(n_clusters = 2) # binary classifications\n","km.fit(X_train)\n","preds = km.predict(X_test)\n","results = pd.DataFrame(X_test)\n","results['KMeans All Vars Predictions'] = preds\n","print(accuracy_score(preds, y_test))\n","\n","km = KMeans(n_clusters = 2) # binary classifications\n","km.fit(X_train1)\n","preds = km.predict(X_test1)\n","results = pd.DataFrame(X_test1)\n","results['KMeans All Vars Predictions'] = preds\n","print(accuracy_score(preds, y_test1))\n","\n","km = KMeans(n_clusters = 2) # binary classifications\n","km.fit(X_train2)\n","preds = km.predict(X_test2)\n","results = pd.DataFrame(X_test2)\n","results['KMeans All Vars Predictions'] = preds\n","print(accuracy_score(preds, y_test2))\n","\n","km = KMeans(n_clusters = 2) # binary classifications\n","km.fit(X_train3)\n","preds = km.predict(X_test3)\n","results = pd.DataFrame(X_test3)\n","results['KMeans All Vars Predictions'] = preds\n","print(accuracy_score(preds, y_test3))\n","\n","\n","display(results)"]},{"cell_type":"markdown","metadata":{},"source":["#### **Results**"]},{"cell_type":"markdown","metadata":{},"source":["a. Interpret the results of each model.\n","i. Do your model estimates seem reasonable? (e.g., provide examples of\n","some model predictions like “for a 30 year old female patient, our model\n","predicts x% risk, whereas for a 30 year old male patient, our model\n","predicts y% risk”)\n","ii. What can you say about your model performance (e.g., based on the\n","evaluation metrics you calculated)?\n","iii. Do you have hypotheses for why your model performed well or not well?\n","b. Compare the performance of your models from part 4 on the evaluation metrics\n","you noted in section 3a.\n","i. What do you conclude?"]},{"cell_type":"markdown","metadata":{},"source":["#### **Contributions**"]},{"cell_type":"markdown","metadata":{},"source":["* Tanvi: \n","* Ella: \n","* Dylan: \n","* Maddy: "]},{"cell_type":"markdown","metadata":{},"source":["#### **Sources Cited**"]},{"cell_type":"markdown","metadata":{},"source":["Must include a citation of the data source(s) in ACM format.\n","b. Must include links to any sources used to assist with coding (do not need to be in\n","ACM format). Remember, any use of generative AI tools such as ChatGPT must\n","be cited including the query used, the answer output, and why you think the\n","answer is correct"]},{"cell_type":"markdown","metadata":{},"source":["Data Set: https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients"]}],"metadata":{"kernelspec":{"display_name":"Python 3.11.4 ('info2950')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"4f30da6fd141dcec1f686a2d3870ea3fbe3345d19df0b7c05e23f27c1e7c07e3"}}},"nbformat":4,"nbformat_minor":2}
